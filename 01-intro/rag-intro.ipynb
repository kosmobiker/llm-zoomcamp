{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b0fd25-41a2-48ad-b9bf-3f1265308bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b37cce2-ed84-408b-9106-d61360aa82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdaf6ce-2540-494f-989c-5b94b1b6626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b9b1f9-3c90-42b0-beb4-cb419f9cdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57de60e5-b96c-499c-a7cf-0f30fc33b324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c499838b-73b3-44be-8ba6-f46d3693aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7d0d18-5c07-4010-9f90-bbd021f110c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f76c2c18dd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d8ea88-7412-49c1-8a8e-44d0d0862a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc00fa8f-fcec-42c0-94ae-7728e0dfa6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I just joined. What should I do next? How can I access course materials?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I don't know math. Can I take the course?\",\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(q, filter_dict={'course': 'machine-learning-zoomcamp'}, num_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df497da4-cee4-463c-a341-acaa14065c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'For ensemble algorithms, during the week 6, one bagging algorithm and one boosting algorithm were presented: Random Forest and XGBoost, respectively.\\nRandom Forest trains several models in parallel. The output can be, for example, the average value of all the outputs of each model. This is called bagging.\\nXGBoost trains several models sequentially: the previous model error is used to train the following model. Weights are used to ponderate the models such as the best models have higher weights and are therefore favored for the final output. This method is called boosting.\\nNote that boosting is not necessarily better than bagging.\\nMélanie Fouesnard\\nBagging stands for “Bootstrap Aggregation” - it involves taking multiple samples with replacement to derive multiple training datasets from the original training dataset (bootstrapping), training a classifier (e.g. decision trees or stumps for Random Forests) on each such training dataset, and then combining the the predictions (aggregation) to obtain the final prediction. For classification, predictions are combined via voting; for regression, via averaging. Bagging can be done in parallel, since the various classifiers are independent. Bagging decreases variance (but not bias) and is robust against overfitting.\\nBoosting, on the other hand, is sequential - each model learns from the mistakes of its predecessor. Observations are given different weights - observations/samples misclassified by the previous classifier are given a higher weight, and this process is continued until a stopping condition is reached (e.g. max. No. of models is reached, or error is acceptably small, etc.). Boosting reduces bias & is generally more accurate than bagging, but can be prone to overfitting.\\nRileen',\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'What is the difference between bagging and boosting?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(\"boosting\", filter_dict={'course': 'machine-learning-zoomcamp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d4792-5985-4aa5-a10f-f61ac83cf32f",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa755a08-b98d-4e92-8994-04e6108499d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef8e9cdc-dfd4-4e54-a332-4b9bde4e6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7da9664-ecb3-4d89-87da-9b2b942444d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[{\"role\": \"user\", \"content\": q}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49432208-13a7-4724-9ba6-a0b7d1b605b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9aQ0FsMCiysOD7RXHmweR1mfokcAg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The possibility of enrolling in a course that has already started depends on several factors, including the specific institution's policies, the instructor's discretion, and the structure of the course. Here are some steps you can take to find out if late enrollment is still an option:\\n\\n1. **Check the Institution’s Policies:** Review the enrollment policies on the institution's website or in the course catalog. Some institutions allow late enrollment within a certain timeframe after the course has begun.\\n\\n2. **Contact the Registrar’s Office:** Reach out to the registrar’s office to inquire about the possibility of enrolling late. They can provide detailed information about deadlines and any additional steps required.\\n\\n3. **Speak with the Instructor:** Contact the course instructor directly. They may allow late enrollments, especially if the course material is self-paced or if you can catch up with the content you missed.\\n\\n4. **Consider the Course Format:** Some courses, particularly online or hybrid ones, might be more flexible with their enrollment deadlines. If the course is part of an open admission or rolling enrollment program, you may have a better chance of joining late.\\n\\n5. **Understand the Impact:** Be prepared to discuss how you plan to catch up on missed work and any potential impacts on your learning. Showing a clear plan can make it more likely that the instructor or institution will accommodate your request.\\n\\n6. **Submit a Petition:** If the standard policies don’t allow for late enrollment, some institutions have a petition process for exceptions. This usually involves explaining your situation and why you were unable to enroll on time.\\n\\nIf you pursue these steps, you'll likely get a clear answer about your options for joining the course after its official start date.\", role='assistant', function_call=None, tool_calls=None))], created=1718466791, model='gpt-4o-2024-05-13', object='chat.completion', system_fingerprint='fp_f4e629d0a5', usage=CompletionUsage(completion_tokens=336, prompt_tokens=18, total_tokens=354))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ec3bde5-4d22-4ed3-9826-3f2c36a3a186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The possibility of enrolling in a course that has already started depends on several factors, including the specific institution's policies, the instructor's discretion, and the structure of the course. Here are some steps you can take to find out if late enrollment is still an option:\n",
      "\n",
      "1. **Check the Institution’s Policies:** Review the enrollment policies on the institution's website or in the course catalog. Some institutions allow late enrollment within a certain timeframe after the course has begun.\n",
      "\n",
      "2. **Contact the Registrar’s Office:** Reach out to the registrar’s office to inquire about the possibility of enrolling late. They can provide detailed information about deadlines and any additional steps required.\n",
      "\n",
      "3. **Speak with the Instructor:** Contact the course instructor directly. They may allow late enrollments, especially if the course material is self-paced or if you can catch up with the content you missed.\n",
      "\n",
      "4. **Consider the Course Format:** Some courses, particularly online or hybrid ones, might be more flexible with their enrollment deadlines. If the course is part of an open admission or rolling enrollment program, you may have a better chance of joining late.\n",
      "\n",
      "5. **Understand the Impact:** Be prepared to discuss how you plan to catch up on missed work and any potential impacts on your learning. Showing a clear plan can make it more likely that the instructor or institution will accommodate your request.\n",
      "\n",
      "6. **Submit a Petition:** If the standard policies don’t allow for late enrollment, some institutions have a petition process for exceptions. This usually involves explaining your situation and why you were unable to enroll on time.\n",
      "\n",
      "If you pursue these steps, you'll likely get a clear answer about your options for joining the course after its official start date.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21237c3-80e9-429c-a089-d45428087046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cc5784e-6515-42e5-be62-8fb915df1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97d35dec-c25f-472d-b961-20d5c30902ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc732688-cbbe-4db9-bd1e-ae414593fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'how do I run kafka?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350e2bde-edee-4d54-b66f-dc93af14a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: how do I run kafka?\n",
      "\n",
      "CONTEXT: \n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
      "answer: In the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Python Kafka: ./build.sh: Permission denied Error\n",
      "answer: Run this command in terminal in the same directory (/docker/spark):\n",
      "chmod +x build.sh\n",
      "\n",
      "section: Project\n",
      "question: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
      "answer: According to https://github.com/dpkp/kafka-python/\n",
      "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\n",
      "Use pip install kafka-python-ng instead\n"
     ]
    }
   ],
   "source": [
    "search_results = search(query)\n",
    "prompt = build_prompt(query, search_results)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8602f40b-ad3b-49c9-b3cc-051a79c888bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fd4497b-c5d5-4258-b950-6b35d1af4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka-based applications like producers, consumers, or kstreams in Java, follow these steps provided in the context:\\n\\nIn the project directory, you need to execute the following command in the terminal:\\n\\n```sh\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nReplace `<jar_name>` with the actual name of your compiled jar file.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "385b012f-4905-422d-8d7c-3d542dfe5a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, even if the course has already started, you can still enroll and are eligible to submit the homework. However, be mindful of the deadlines for turning in the final projects. It's important not to leave everything for the last minute.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('the course has already started, can I still enroll?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a18445-b0f1-4602-b929-528ab587225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided CONTEXT does not contain specific information on how to perform joins using PySpark. If you need to perform joins in PySpark, you typically use the DataFrame API which allows you to perform various types of joins such as inner, outer, left, and right joins. Here is a basic example of how to perform a join in PySpark:\\n\\nAssuming you have two DataFrames, `df1` and `df2`:\\n\\n```python\\n# Inner Join\\nresult = df1.join(df2, df1[\"key\"] == df2[\"key\"], \"inner\")\\n\\n# Left Outer Join\\nresult = df1.join(df2, df1[\"key\"] == df2[\"key\"], \"left_outer\")\\n\\n# Right Outer Join\\nresult = df1.join(df2, df1[\"key\"] == df2[\"key\"], \"right_outer\")\\n\\n# Full Outer Join\\nresult = df1.join(df2, df1[\"key\"] == df2[\"key\"], \"outer\")\\n\\n# Cross Join\\nresult = df1.crossJoin(df2)\\n```\\n\\nIn these examples:\\n- `df1` and `df2` are DataFrames.\\n- `\"key\"` is the column on which you are performing the join.\\n- `\"inner\"`, `\"left_outer\"`, `\"right_outer\"`, and `\"outer\"` specify the type of join.\\n\\nThis should give you a starting point for performing joins with Spark using PySpark.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how to use spark to make joins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72f16d-7b2f-480c-9b3e-6dbf8da0529b",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c05052f-a85a-4137-8398-0fd0be678599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a78df1cc-5a5a-40b4-b673-19c7f0319453",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7be661cb-18a5-4ac8-8e11-4722cb7642b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3cbc31fe41ed',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'sfyC9chHRoSSF3OqTT6f1g',\n",
       " 'version': {'number': '8.4.3',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73',\n",
       "  'build_date': '2022-10-04T07:17:24.662462378Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.3.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9367c18-41ad-495e-9920-1a0c552f0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "# es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f778c93-a5b6-4634-b42e-0c25083a2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c230059-e219-4a13-a7f8-ede4cf1b028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70fe3c97-916d-42c0-bd7b-4f42d9056409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 948/948 [00:06<00:00, 150.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1bc1244-b8dc-4228-8171-c0507004db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just disovered the course. Can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c72e000-910b-4fb5-aa88-2561e7bc39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81abecbc-eb6b-428f-ab7d-7e21f58b64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ea9315a-a619-4066-9e90-8c260f2c8450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you can still join the course even if it has already started. You don't need to register beforehand, and you are still eligible to submit the homework assignments. Just be mindful of the deadlines for turning in the final projects.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b22feffd-006e-4f8f-b35c-23c4ae8fa0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided FAQ database does not have specific instructions about installing Spark. However, I can give you a general guide on how to approach it:\\n\\n1. **Download Spark**: \\n   Visit the [Apache Spark website](https://spark.apache.org/downloads.html) and download the pre-built package for Hadoop. Select the version matching your Hadoop version.\\n\\n2. **Extract the Spark Archive**:\\n   ```bash\\n   tar -xvf spark-<version>-bin-hadoop<version>.tgz\\n   ```\\n\\n3. **Set Environment Variables**:\\n   Update your `.bashrc` or `.bash_profile` to include the following lines:\\n   ```bash\\n   export SPARK_HOME=~/path/to/spark\\n   export PATH=$SPARK_HOME/bin:$PATH\\n   ```\\n\\n4. **Start Spark**:\\n   Navigate to the Spark directory:\\n   ```bash\\n   cd $SPARK_HOME\\n   ./bin/spark-shell\\n   ```\\nThis will launch the Spark shell with Scala.\\n\\n5. **Launching a Cluster** (if needed):\\n   For running a standalone cluster, follow the steps mentioned in the CONTEXT:\\n   ```bash\\n   # Start the Spark Master\\n   $SPARK_HOME/bin/spark-class org.apache.spark.deploy.master.Master --host localhost\\n\\n   # Start a Spark Worker\\n   $SPARK_HOME/bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077 --host localhost\\n   ```\\n\\nThese steps provide a basic setup for installing and running Spark. For detailed instructions and troubleshooting, refer to the [official documentation](https://spark.apache.org/docs/latest/).'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How to install Spark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d3904-ae78-4d9b-b8c7-3d72df3fbed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
