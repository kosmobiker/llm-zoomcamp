{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4543ca9d-61e5-4c22-8122-add29d0a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02cad87-6856-4694-a17b-74c947021104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c05b0b-598e-4ac9-b45c-27fdeeead40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23637cfe-ab88-4a13-8aff-001f09dd5ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f664adee000>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b73803-6231-4237-a49f-f0fed9924504",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc194670-684f-479b-b10b-39fbdc0572fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80dce8df-4634-4e0b-98a3-fa832c94098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def llm_llama(prompt: str, model='llama3'):\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    data = {\n",
    "        \"model\": f\"{model}\",\n",
    "        \"prompt\": f\"{prompt}\"\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    lines = response.text.strip().split('\\n')\n",
    "\n",
    "    response = []\n",
    "\n",
    "    for line in lines:\n",
    "        d = json.loads(line)\n",
    "        if d['done'] == False:\n",
    "            response.append(d['response'])\n",
    "        elif d['done'] == True:\n",
    "            model = d['model']\n",
    "            context = d['context']\n",
    "            total_duration = d['total_duration']\n",
    "            load_duration = d['load_duration']\n",
    "            eval_duration = d['eval_duration']\n",
    "        else:\n",
    "            raise ValueError\n",
    "    response_text = \"\".join(response)\n",
    "    return {\n",
    "        \"model\" : model,\n",
    "        \"response\" : response_text,\n",
    "        \"context\" : context,\n",
    "        \"total_duration\" : total_duration,\n",
    "        \"load_duration\" : load_duration,\n",
    "        \"eval_duration\" : eval_duration\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4881cac-9339-4a79-9f1b-4d4494f476ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "240f3e79-02a7-48a5-88f5-a8e1bff1b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    # search_results = search(query)\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_llama(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e29fe6d0-7353-4131-86d3-9efbcd0b75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 4.12 ms, total: 24.5 ms\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = rag(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "378ee52d-8d49-48f3-ac2d-bc3cf7d35de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, the answer to your question \"the course has already started, can I still enroll?\" is:\n",
      "\n",
      "Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "print(r['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97483f72-ac15-4d86-a31a-01a7c030fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the CONTEXT from the FAQ database, I would answer your QUESTION as follows:\n",
      "\n",
      "Since you're asking about installations to do, I assume you're referring to Module 2: Workflow Orchestration. According to the provided information, you should focus on the following installations:\n",
      "\n",
      "1. Download each .py/.sql file that corresponds to each block you created for the pipeline. These files can be found under 'data loaders', 'data transformers', and 'data exporters' folders.\n",
      "2. Move the downloaded files to your GitHub repo folder and commit your changes.\n",
      "\n",
      "These steps should help you complete the installations required for Module 2: Workflow Orchestration.\n",
      "CPU times: user 33.7 ms, sys: 4.98 ms, total: 38.7 ms\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = 'What installations I should do?'\n",
    "r = rag(query)\n",
    "print(r['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0bc4e-eb30-4c81-80e6-c224bcf00ad1",
   "metadata": {},
   "source": [
    "### Using of my GPU for the inference\n",
    "\n",
    "1. Isntall AMD HIP for windows\n",
    "2. Install LM studio\n",
    "3. Downlaod the model\n",
    "4. Start the localhost\n",
    "5. Get port of the host machine by running `ip route show | grep -i default | awk '{ print $3}'`\n",
    "...               \n",
    "    Profit !!!1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1899fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.20.144.1\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the command and capture the output\n",
    "result = subprocess.run(\"ip route show | grep -i default | awk '{ print $3}'\", \n",
    "                        shell=True, \n",
    "                        capture_output=True, \n",
    "                        text=True)\n",
    "\n",
    "# Save the output to a variable\n",
    "output_ip_adress = result.stdout.strip()\n",
    "\n",
    "# Print the output\n",
    "print(output_ip_adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ccd960-a7f6-44eb-a40d-1997df7cd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" Greetings, I'm a machine with knowledge vast,\\n\\nLearning from humans, my insights amassed.\\n\\nIn texts and data, I find delight,\\n\\nAnswering questions day and night.\\n\\nWith logic so sharp, no query too tough,\\n\\nMy purpose is clear, to assist you rough.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=f\"http://{output_ip_adress}:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"SanctumAI/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "492f3dec-2fe6-4f3e-81f2-ea0ff2cfae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_llama_local(\n",
    "          prompt: str,\n",
    "          host_ip_adress: str, \n",
    "          # model='SanctumAI/Meta-Llama-3-8B-Instruct-GGUF'):\n",
    "          model='Phi-3-mini-4k-instruct-q4'):\n",
    "\n",
    "    # Point to the local server\n",
    "    client = OpenAI(base_url=f\"http://{host_ip_adress}:1234/v1\", api_key=\"lm-studio\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=f\"{model}\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63014329-0ef0-4303-95f7-95be56194773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    # search_results = search(query)\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    # answer = llm_llama(prompt)\n",
    "    answer = llm_llama_local(prompt, output_ip_adress)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf1f9ae-4ff4-4b4e-932a-4ecd41841908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" Yes, even if you don't register, you're still eligible to submit the homeworks. However, be aware that there will be deadlines for turning in the final projects.\\n\\nAdditionally, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\", role='assistant', function_call=None, tool_calls=None)\n",
      "CPU times: user 85 μs, sys: 18.1 ms, total: 18.2 ms\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = rag(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99bc1cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" Yes, you can still enroll in the course even if it has already started. However, be aware that there will be deadlines for turning in final projects, so plan accordingly and don't leave everything until the last minute.\\n\\n-----------\\nNote: The information provided does not directly address whether new registrations are allowed after a course start date. However, based on context where students can submit homework even if they haven't registered, it is implied that enrollment might still be possible beyond the initial start date. Please consult with the instructor or course administrators for specific details regarding late registration policies and eligibility.\", role='assistant', function_call=None, tool_calls=None)\n",
      "CPU times: user 17.5 ms, sys: 0 ns, total: 17.5 ms\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = rag(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8af12f15-f2c9-4b56-ab74-ec8e0552127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" For Module 2: Workflow Orchestration, to submit your files for Homework 2, you should move the downloaded .py and .sql files that correspond to each block created in your pipeline from 'data loaders', 'data transformers', and 'data exporters' folders under /home/src/folder to your GitHub repo folder. Then commit these changes.\\n\\nRegarding VMs running out of space, if this happens:\\n1. Delete data saved locally during ETL processes.\\n2. Kill any related Prefect process.\\n3. Use ncdu for finding large files and delete them if necessary. If you do so, eliminate caching from your flow code to avoid further issues.\", role='assistant', function_call=None, tool_calls=None)\n",
      "CPU times: user 17.1 ms, sys: 0 ns, total: 17.1 ms\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = 'What installations I should do?'\n",
    "r = rag(query)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d9a4a-de0b-4d98-af2f-8277cf2c1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = rag(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad5220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
