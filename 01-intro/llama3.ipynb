{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4543ca9d-61e5-4c22-8122-add29d0a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c02cad87-6856-4694-a17b-74c947021104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c05b0b-598e-4ac9-b45c-27fdeeead40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23637cfe-ab88-4a13-8aff-001f09dd5ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f664adee000>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b73803-6231-4237-a49f-f0fed9924504",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc194670-684f-479b-b10b-39fbdc0572fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80dce8df-4634-4e0b-98a3-fa832c94098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def llm_llama(prompt: str, model='llama3'):\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    data = {\n",
    "        \"model\": f\"{model}\",\n",
    "        \"prompt\": f\"{prompt}\"\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    lines = response.text.strip().split('\\n')\n",
    "\n",
    "    response = []\n",
    "\n",
    "    for line in lines:\n",
    "        d = json.loads(line)\n",
    "        if d['done'] == False:\n",
    "            response.append(d['response'])\n",
    "        elif d['done'] == True:\n",
    "            model = d['model']\n",
    "            context = d['context']\n",
    "            total_duration = d['total_duration']\n",
    "            load_duration = d['load_duration']\n",
    "            eval_duration = d['eval_duration']\n",
    "        else:\n",
    "            raise ValueError\n",
    "    response_text = \"\".join(response)\n",
    "    return {\n",
    "        \"model\" : model,\n",
    "        \"response\" : response_text,\n",
    "        \"context\" : context,\n",
    "        \"total_duration\" : total_duration,\n",
    "        \"load_duration\" : load_duration,\n",
    "        \"eval_duration\" : eval_duration\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4881cac-9339-4a79-9f1b-4d4494f476ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "240f3e79-02a7-48a5-88f5-a8e1bff1b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    # search_results = search(query)\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_llama(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e29fe6d0-7353-4131-86d3-9efbcd0b75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 4.12 ms, total: 24.5 ms\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = rag(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "378ee52d-8d49-48f3-ac2d-bc3cf7d35de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, the answer to your question \"the course has already started, can I still enroll?\" is:\n",
      "\n",
      "Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "print(r['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97483f72-ac15-4d86-a31a-01a7c030fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the CONTEXT from the FAQ database, I would answer your QUESTION as follows:\n",
      "\n",
      "Since you're asking about installations to do, I assume you're referring to Module 2: Workflow Orchestration. According to the provided information, you should focus on the following installations:\n",
      "\n",
      "1. Download each .py/.sql file that corresponds to each block you created for the pipeline. These files can be found under 'data loaders', 'data transformers', and 'data exporters' folders.\n",
      "2. Move the downloaded files to your GitHub repo folder and commit your changes.\n",
      "\n",
      "These steps should help you complete the installations required for Module 2: Workflow Orchestration.\n",
      "CPU times: user 33.7 ms, sys: 4.98 ms, total: 38.7 ms\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = 'What installations I should do?'\n",
    "r = rag(query)\n",
    "print(r['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0bc4e-eb30-4c81-80e6-c224bcf00ad1",
   "metadata": {},
   "source": [
    "### Using of my GPU for the inference\n",
    "\n",
    "1. Isntall AMD HIP for windows\n",
    "2. Install LM studio\n",
    "3. Downlaod the model\n",
    "4. Start the localhost\n",
    "5. Get port of the host machine by running `ip route show | grep -i default | awk '{ print $3}'`\n",
    "...               \n",
    "    Profit !!!1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ccd960-a7f6-44eb-a40d-1997df7cd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I'm a chatbot so fine,\\nA language model, one of a kind in its prime.\\nI'll respond to your queries with glee,\\nIn rhymes, of course, that's just part of me!\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://172.20.144.1:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"SanctumAI/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "492f3dec-2fe6-4f3e-81f2-ea0ff2cfae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_llama_local(prompt: str, model='SanctumAI/Meta-Llama-3-8B-Instruct-GGUF'):\n",
    "    # Point to the local server\n",
    "    client = OpenAI(base_url=\"http://172.20.144.1:1234/v1\", api_key=\"lm-studio\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=f\"{model}\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63014329-0ef0-4303-95f7-95be56194773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    # search_results = search(query)\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    # answer = llm_llama(prompt)\n",
    "    answer = llm_llama_local(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bf1f9ae-4ff4-4b4e-932a-4ecd41841908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Based on the CONTEXT from the FAQ database, I can answer your question.\\n\\nAccording to the context, the course has already started. In this case, you can still enroll, but be aware that there will be deadlines for turning in the final projects. You can start by installing and setting up all the dependencies and requirements mentioned earlier, and look over the prerequisites and syllabus to see if you are comfortable with these subjects.', role='assistant', function_call=None, tool_calls=None)\n",
      "CPU times: user 113 ms, sys: 0 ns, total: 113 ms\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = rag(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af12f15-f2c9-4b56-ab74-ec8e0552127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Based on the context from the FAQ database, I\\'ll answer your question:\\n\\nWhat installations should you do?\\n\\nAccording to the \"Course - What can I do before the course starts?\" section, it is recommended that you start by installing and setting up all the dependencies and requirements:\\n\\n1. Google cloud account\\n2. Google Cloud SDK\\n3. Python 3 (installed with Anaconda)\\n4. Terraform\\n5. Git\\n\\nThese installations should be done before the course starts to ensure a smooth learning experience.', role='assistant', function_call=None, tool_calls=None)\n",
      "CPU times: user 17.3 ms, sys: 0 ns, total: 17.3 ms\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = 'What installations I should do?'\n",
    "r = rag(query)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d9a4a-de0b-4d98-af2f-8277cf2c1155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
